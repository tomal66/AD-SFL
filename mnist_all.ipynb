{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MNIST All Experiments (Multi-GPU Parallel)\n",
                "\n",
                "This notebook runs a comprehensive set of experiments for the AD-SFL project on the MNIST dataset.\n",
                "\n",
                "**Configurations:**\n",
                "- **Seeds:** 3 different random seeds\n",
                "- **Distributions:** IID, Non-IID\n",
                "- **Poison Ratios:** 0.0, 0.3, 0.5, 0.7\n",
                "- **Attacks:** Label Flip, Backdoor\n",
                "- **Fixed Parameters:** \n",
                "    - Clients: 10\n",
                "    - Rounds: 25\n",
                "    - Defense: SafeSplit (Enabled)\n",
                "\n",
                "**Hardware:**\n",
                "- Supports parallel execution on multiple GPUs (e.g. 2x T4 on Kaggle).\n",
                "- Automatically detects available GPUs and distributes work."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile experiment_runner.py\n",
                "import os\n",
                "import sys\n",
                "import traceback\n",
                "\n",
                "def run_worker_chunk(gpu_id, configs):\n",
                "    \"\"\"\n",
                "    Worker function to run a chunk of experiments on a specific GPU.\n",
                "    Sets CUDA_VISIBLE_DEVICES to isolate the GPU for this process.\n",
                "    \"\"\"\n",
                "    # Set GPU isolation BEFORE importing torch/simulation\n",
                "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
                "    \n",
                "    import torch\n",
                "    # Import simulation here to ensure it sees the specific GPU as cuda:0\n",
                "    import simulation\n",
                "    \n",
                "    results = []\n",
                "    \n",
                "    print(f\"[Worker GPU {gpu_id}] Started. Processing {len(configs)} configs.\")\n",
                "    \n",
                "    for i, config in enumerate(configs):\n",
                "        try:\n",
                "            # print(f\"[Worker GPU {gpu_id}] Running exp {i+1}/{len(configs)}: {config['attack_type']} | ratio {config['poison_ratio']}\")\n",
                "            hist = simulation.run_simulation(config)\n",
                "            results.append({\n",
                "                'config': config, \n",
                "                'acc': hist['acc'][-1], \n",
                "                'asr': hist['asr'][-1],\n",
                "                'error': None\n",
                "            })\n",
                "        except Exception as e:\n",
                "            print(f\"[Worker GPU {gpu_id}] Error in exp {i+1}: {e}\")\n",
                "            traceback.print_exc()\n",
                "            results.append({\n",
                "                'config': config,\n",
                "                'acc': 0.0,\n",
                "                'asr': 0.0,\n",
                "                'error': str(e)\n",
                "            })\n",
                "            \n",
                "    print(f\"[Worker GPU {gpu_id}] Finished.\")\n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "import scipy.stats as stats\n",
                "import random\n",
                "from collections import defaultdict\n",
                "import torch.multiprocessing as mp\n",
                "# Ensure we can import from the current directory\n",
                "\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "# Import our runner module (just created)\n",
                "import experiment_runner\n",
                "\n",
                "# Force spawn method for safe GPU multiprocessing\n",
                "try:\n",
                "    mp.set_start_method('spawn', force=True)\n",
                "except RuntimeError:\n",
                "    pass\n",
                "\n",
                "# Auto-install dependencies if needed\n",
                "# !pip install torch torchvision numpy scipy matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "SEEDS = [42, 100, 2024]\n",
                "\n",
                "DISTRIBUTIONS = ['iid', 'non_iid']\n",
                "POISON_RATIOS = [0.0, 0.3, 0.5, 0.7]\n",
                "ATTACKS = ['label_flip', 'backdoor']\n",
                "\n",
                "# Fixed params\n",
                "NUM_CLIENTS = 10\n",
                "ROUNDS = 25\n",
                "DEFENSE_ENABLED = True\n",
                "DATASET = 'mnist'\n",
                "\n",
                "# Attack specific params\n",
                "BACKDOOR_SOURCE_LABELS = [1, 2, 3]\n",
                "BACKDOOR_TARGET_LABEL = 8\n",
                "\n",
                "# Generate all configurations\n",
                "all_configs = []\n",
                "for seed in SEEDS:\n",
                "    for dist in DISTRIBUTIONS:\n",
                "        for ratio in POISON_RATIOS:\n",
                "            for attack in ATTACKS:\n",
                "                config = {\n",
                "                    \"num_clients\": NUM_CLIENTS,\n",
                "                    \"rounds\": ROUNDS,\n",
                "                    \"poison_ratio\": ratio,\n",
                "                    \"dataset\": DATASET,\n",
                "                    \"distribution\": dist,\n",
                "                    \"defense_enabled\": DEFENSE_ENABLED,\n",
                "                    \"attack_type\": attack,\n",
                "                    \"batch_size\": 32,\n",
                "                    \"test_batch_size\": 256,\n",
                "                    # Specifics\n",
                "                    \"source_labels\": BACKDOOR_SOURCE_LABELS if attack == 'backdoor' else None,\n",
                "                    \"target_label\": BACKDOOR_TARGET_LABEL if attack == 'backdoor' else 0,\n",
                "                    # Metadata for aggregation\n",
                "                    \"meta_seed\": seed,\n",
                "                    \"meta_dist\": dist,\n",
                "                    \"meta_ratio\": ratio,\n",
                "                    \"meta_attack\": attack\n",
                "                }\n",
                "                all_configs.append(config)\n",
                "\n",
                "print(f\"Total Experiments to Run: {len(all_configs)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def set_seed(seed):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "# Distribution Logic\n",
                "num_gpus = torch.cuda.device_count()\n",
                "if num_gpus == 0:\n",
                "    print(\"No generic GPU detected. Running sequentially on CPU/single device (slow).\")\n",
                "    num_workers = 1\n",
                "    gpu_indices = [0] # Dummy\n",
                "else:\n",
                "    print(f\"Detected {num_gpus} GPUs. Parallelizing...\")\n",
                "    num_workers = num_gpus\n",
                "    gpu_indices = list(range(num_gpus))\n",
                "\n",
                "# Set seeds for main process\n",
                "# (Individual runs set their own seeds via torch/numpy inside run_simulation if needed, \n",
                "# but simulation.py usually relies on global state. \n",
                "# Since we use multiprocessing spawn, each process starts fresh.)\n",
                "\n",
                "# Split configs\n",
                "chunks = [[] for _ in range(num_workers)]\n",
                "for i, conf in enumerate(all_configs):\n",
                "    chunks[i % num_workers].append(conf)\n",
                "\n",
                "print(f\"Work distribution: {[len(c) for c in chunks]} runs per worker.\")\n",
                "\n",
                "if __name__ == '__main__':\n",
                "    # pool.starmap needs importable func. experiment_runner.run_worker_chunk is importable.\n",
                "    with mp.Pool(processes=num_workers) as pool:\n",
                "        args = [(gpu_indices[i], chunks[i]) for i in range(num_workers)]\n",
                "        results_nested = pool.starmap(experiment_runner.run_worker_chunk, args)\n",
                "        \n",
                "    # Flatten results\n",
                "    all_results = []\n",
                "    for worker_res in results_nested:\n",
                "        all_results.extend(worker_res)\n",
                "        \n",
                "    print(\"\\nAll experiments completed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aggregation and Reporting\n",
                "results_agg = defaultdict(list)\n",
                "\n",
                "for res in all_results:\n",
                "    if res.get('error'):\n",
                "        print(f\"Skipping failed run: {res['config']['meta_dist']} | {res['config']['meta_ratio']} | {res['config']['meta_attack']} - Error: {res['error']}\")\n",
                "        continue\n",
                "        \n",
                "    dist = res['config']['meta_dist']\n",
                "    ratio = res['config']['meta_ratio']\n",
                "    attack = res['config']['meta_attack']\n",
                "    \n",
                "    results_agg[(dist, ratio, attack)].append((res['acc'], res['asr']))\n",
                "\n",
                "def mean_confidence_interval(data, confidence=0.95):\n",
                "    a = 1.0 * np.array(data)\n",
                "    n = len(a)\n",
                "    if n < 2: return np.mean(a), 0.0\n",
                "    m, se = np.mean(a), scipy.stats.sem(a)\n",
                "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
                "    return m, h\n",
                "\n",
                "import scipy\n",
                "\n",
                "print(\"\\n\\n=== Final Aggregated Results (3 Seeds) ===\")\n",
                "print(f\"{'Distribution':<12} | {'Ratio':<6} | {'Attack':<12} | {'Accuracy (Mean ± 95% CI)':<30} | {'ASR (Mean ± 95% CI)':<30}\")\n",
                "print(\"-\"*100)\n",
                "\n",
                "sorted_keys = sorted(results_agg.keys(), key=lambda x: (x[0], x[1], x[2]))\n",
                "\n",
                "for key in sorted_keys:\n",
                "    dist, ratio, attack = key\n",
                "    values = results_agg[key]\n",
                "    \n",
                "    if not values:\n",
                "        continue\n",
                "        \n",
                "    accs = [v[0] for v in values]\n",
                "    asrs = [v[1] for v in values]\n",
                "    \n",
                "    acc_m, acc_ci = mean_confidence_interval(accs)\n",
                "    asr_m, asr_ci = mean_confidence_interval(asrs)\n",
                "    \n",
                "    print(f\"{dist:<12} | {ratio:<6} | {attack:<12} | {acc_m:.2f} ± {acc_ci:.2f}%{'':<18} | {asr_m:.2f} ± {asr_ci:.2f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
